---
title: "Régression linéaire multiple"
author: "Guyliann Engels & Philippe Grosjean"
description: "**SDD II Module 2** Résumé de lm et régression linéaire multiple."
tutorial:
  id: "B02La_reg_multi"
  version: 2.4.0/11
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
BioDataScience2::learnr_setup()
SciViews::R("model",lang = "fr")

# fat -----
fat <- read("fat", package = "faraway")
# lm
fat_lm1 <- lm(data = fat, density ~ abdom)
lm_lin_result <- tidy(fat_lm1)
lm_lin_param <- glance(fat_lm1)
# lm multi
fat_lm2 <- lm(data = fat, density ~ abdom + thigh)
lm_mult_result <- tidy(fat_lm2)
lm_mult_param <- glance(fat_lm2)

# diabetes -----
diabetes <- read("diabetes", package = "faraway")
diabetes <- janitor::clean_names(diabetes)
diabetes <- smutate(diabetes, weight = weight * 0.453592)
diabetes <- smutate(diabetes, 
  map  = bp_1d + 1/3 * (bp_1s - bp_1d),
  age2 = age^2)
is.labelled <- function(x) inherits(x, c("labelled", "haven_labelled"))
diabetes <- smutate(diabetes, across(sapply(diabetes, is.labelled), .fns = as.numeric))
diabetes <- labelise(diabetes, 
  label = list(map = "Tension artérielle moyenne", age = "Âge"), 
  units = list(map = "mm Hg", age = "années")
)
# lm multi
map_lm <- lm(data = diabetes, map ~ age + chol + weight)
map_lm_coef <- tidy(map_lm)
map_lm_param <- glance(map_lm)
```

```{r, echo=FALSE}
BioDataScience2::learnr_banner()
```

```{r, context="server"}
BioDataScience2::learnr_server(input, output, session)
```

------------------------------------------------------------------------

## Objectifs

Le premier module vous a permis de vous familiariser avec la régression linéaire. Vous avez appris à interpréter une partie des résultats renvoyés dans le résumé du modèle, ainsi qu'à réaliser et interpréter les graphiques d'analyse des résidus. Les objectifs de ce tutoriel sont :

-   Être capable de lire la sortie renvoyée par `summary()` pour un objet **lm**.
-   Maîtriser la régression linéaire multiple dans R avec la fonction `lm()`.

## Masse grasse et densité corporelle

![La masse grasse influe-t-elle la densité corporelle ? Photo de [Andres Ayrton](https://www.pexels.com/photo/crop-plump-woman-touching-abdomen-6550872/)](images/body_fat.jpg)

Le tableau de données `fat` traite du pourcentage de masse grasse de 252 hommes. Les participants à cette étude ont été mesurés sous toutes les coutures, et ensuite, leur densité corporelle a été déterminée avec précision par un procédé d'immersion dans l'eau. Cette méthode, bien que très fiable, n'est pas des plus simples à mettre en œuvre. Les scientifiques font donc appel à vous pour déterminer s'il est possible de prédire la densité corporelle à l'aide de mesures biométriques plus simples à obtenir et avec quelle précision.

```{r, echo=TRUE}
SciViews::R("model",lang = "fr") # Configuration du système

fat <- read("fat", package = "faraway")
skimr::skim(fat)
```

## Régression linéaire simple

Vous allez modéliser la densité (`density` en g/cm^3^) des participants en fonction de leur tour de taille (`abdom` en cm). Le graphique ci-dessous vous présente le nuage de points correspondant.

```{r, echo=TRUE}
chart(data = fat, density ~ abdom) +
  geom_point() +
  labs(x = "Tour de taille [cm]", y = "Densité [g/cm^3]")
```

Calculez maintenant une régression linéaire simple de `density` en fonction de `abdom` du jeu de données `fat`. Vous placerez le résultat dans `fat_lm1` et vous imprimerez le résumé.

```{r reglin_h2, exercise=TRUE}
summary(fat_lm1 <- lm(data = ___, ___ ~ ___))
```

```{r reglin_h2-hint}
summary(fat_lm1 <- lm(data = DF, FORMULA))

#### ATTENTION: Hint suivant = solution !####
```

```{r reglin_h2-solution}
## Solution ##
summary(fat_lm1 <- lm(data = fat, density ~ abdom))
```

```{r reglin_h2-check}
grade_code("D'accord, on a maintenant une régression linéaire simple comme point de départ.")
```

Analysez le tableau des résultats et répondez aux questions suivantes :

```{r qu_reglin}
quiz(
  question(text = "Quelle est la valeur de l'ordonnée à l'origine ?",
    answer(sprintf("%.4f", lm_lin_result$estimate[1]), correct = TRUE),
    answer(sprintf("%.4f", 0)),
    answer(sprintf("%.4f", lm_lin_param$sigma[1])),
    answer(sprintf("%.4f", lm_lin_result$estimate[2])),
    answer(sprintf("%.4f", lm_lin_param$r.squared[1])),
    allow_retry = TRUE, random_answer_order = TRUE
  ),
  question(text = "Quelle est la valeur de la pente ?",
    answer(sprintf("%.4f", 0)),
    answer(sprintf("%.4f", lm_lin_result$estimate[2]), correct = TRUE),
    answer(sprintf("%.4f", lm_lin_param$BIC[1])),
    answer(sprintf("%.4f", lm_lin_result$estimate[1])),
    answer(sprintf("%.4f", lm_lin_param$r.squared[1])),
    allow_retry = TRUE, random_answer_order = TRUE
  ),
  question(text = "Quelle est la fraction de la variance exprimée par la régression linéaire ?",
    answer(sprintf("%.4f", lm_lin_param$r.squared), correct = TRUE),
    answer(sprintf("%.4f", lm_lin_param$statistic)),
    answer(sprintf("%.4f", as.numeric(lm_lin_param$df))),
    answer(sprintf("%.4f", lm_lin_result$estimate[1])),
    allow_retry = TRUE, random_answer_order = TRUE
  )
)
```

L'analyse des résidus n'est pas l'objectif de ce tutoriel. Prenez cependant le temps d'interpréter chaque graphique pour déterminer si la régression linéaire est justifiée ici.

```{r}
chart$residuals(fat_lm1)
```

## Régression linéaire multiple

Complétez à présent votre modèle en incluant le tour de cuisse (`thigh` en cm) comme variable explicative supplémentaire par rapport au modèle précédent. Voici deux nuages de points pour vous donner une idée...

```{r, echo=TRUE}
chart(data = fat, density ~ thigh) +
  geom_point() +
  labs(x = "Tour de cuisse [cm]", y = "Densité [g/cm^3]")
```

```{r, echo=TRUE}
chart(data = fat, thigh ~ abdom) +
  geom_point() +
  labs(x = "Tour de cuisse [cm]", y = "Tour de taille [cm]")
```

> Lorsque vous incluez des variables dans une régression linéaire multiple, vérifiez toujours la corrélation entre elles. Des variables trop fortement corrélées (avec des coefficients tendant vers un en valeur absolue) n'apporteront rien : elles sont "synonymes" en quelque sorte. Mais pis, elles risquent de rendre la détermination des paramètres du modèle instable.

Voici la matrice de corrélation entre les trois variables considérées.

```{r, echo=TRUE}
correlation(fat[, c("density", "abdom", "thigh")])
```

La corrélation linéaire entre `density` et `abdom` est bonne. Elle l'est moins entre `density` et `thigh`, mais nous allons voir dans un instant si cette variable apporte un plus. La corrélation entre `abdom` et `thigh` est assez élevée (77%) mais cela laisse un peu de marge pour exprimer éventuellement une information complémentaire utile au sein du modèle multiple.

```{r regmulti_h2, exercise=TRUE}
# régression multiple 
summary(fat_lm2 <- lm(data = ___, ___ ~ ___))
```

```{r regmulti_h2-hint}
summary(fat_lm2 <- lm(data = DF, Y  ~ VAR1 + VAR2))

#### ATTENTION: Hint suivant = solution !####
```

```{r regmulti_h2-solution}
## Solution ## 
summary(fat_lm2 <- lm(data = fat, density ~ abdom + thigh))
```

```{r regmulti_h2-check}
grade_code("Vous venez de réaliser votre première régression linéaire multiple. Est-elle meilleure que la régression simple !")
```

Suite à votre analyse, répondez aux questions suivantes :

```{r qu_regmulti}
quiz(
  question(text = "Quelle est la valeur de l'écart-type résiduel de ce modèle ?",
    answer(sprintf("%.4f", lm_mult_param$sigma[1]), correct = TRUE),
    answer(sprintf("%.4f", lm_mult_result$estimate[2])),
    answer(sprintf("%.4f", lm_mult_result$p.value[1])),
    answer(sprintf("%.4f", lm_mult_param$AIC[1])),
    answer(sprintf("%.4f", lm_mult_param$r.squared[1])),
    allow_retry = TRUE, random_answer_order = TRUE
  ),
  question(text = "Quelle est la fraction de la variance exprimée par la régression linéaire ?",
    answer(sprintf("%.4f", lm_mult_param$adj.r.squared), correct = TRUE),
    answer(sprintf("%.4f", lm_mult_param$r.squared)),
    answer(sprintf("%.4f", lm_mult_param$df)),
    answer(sprintf("%.4f", lm_mult_result$estimate[1])),
    allow_retry = TRUE, random_answer_order = TRUE
  )
)
```

Voici le graphique composite de l'analyse des résidus pour notre modèle multiple. Y-voyez-vous des anomalies ?

```{r}
chart$residuals(fat_lm2)
```

En réalité, les résidus ont un comportement très, très similaire entre les deux modèles et les problèmes visibles le sont à cause de points extrêmes qui étaient d'ailleurs identifiables dès le départ sur les graphiques en nuage de points.

## Choix du meilleur modèle

Vous venez de réaliser deux modèles. Il s'agit d'un cas particulier. Ces deux modèles sont imbriqués, ce qui signifie que l'un est une version simplifiée (avec un ou plusieurs paramètres en moins) de l'autre. Comment pourriez-vous départager ces deux modèles ? Dans un tel cas, une ANOVA permet de comparer les deux et de tirer une conclusion. Avant de faire notre test, décidons de fixer alpha à 5%. L'hypothèse nulle est que les deux modèles sont identiques. L'hypothèse alternative que le modèle plus complexe apporte un gain.

```{r, echo=TRUE}
anova(fat_lm1, fat_lm2)
```

Le critère d'Akaike est une métrique adaptée à la comparaison de modèles. Le meilleur modèle selon le critère d'Akaike est le modèle ayant obtenu la valeur la plus faible.

```{r}
AIC(fat_lm1, fat_lm2)
```

Dans les deux cas, c'est le modèle multiple qui sort gagnant, mais de peu. En effet, la valeur P de l'ANOVA étant légèrement supérieure à 1%, elle est moyenne, mais reste inférieure au seuil alpha de 5% choisi. Nous rejetons donc l'hypothèse nulle. D'autre part, le critère d'Akaike est très, très légèrement plus faible en faveur du modèle multiple. C'est ténu et le gain en terme de part de variance expliquée (R^2^) l'est aussi puisque l'on ne gagne même pas un pour cent. Donc, malgré ces résultats en faveur du modèle multiple, nous pourrions aussi légitimement considérer que la simplicité de la régression linéaire simple nous fait préférer cette dernière. Tout est affaire de compromis en statistiques. Naturellement, nous avons encore d'autres variables à explorer, mais laissons ce jeu de données pour en aborder un autre...

## Hypertension

L'hypertension est un des maux du siècle. Elle est liée à de nombreux facteurs. La tension artérielle dépend naturellement du cœur. Un cycle cardiaque se décompose en deux parties. La contraction cardiaque est la systole et la relaxation cardiaque est la diastole. On peut mesurer la pression de chaque phase à l'aide d'un tensiomètre. La mesure est exprimée en millimètre de mercure. La valeur de référence est de 140/90 mm Hg. La valeur de 140 représente la pression systolique (**SP**) et la valeur de 90 la pression diastolique (**DP**). Une tension comprise entre 100/70 et 140/90 mmHg va être considérée comme normale.

![Mesure de la tension artérielle, photo de [Pavel Danilyuk, Pexels](https://www.pexels.com/photo/a-healthcare-worker-measuring-a-patient-s-blood-pressure-using-a-sphygmomanometer-7108344/).](images/blood_pressure.jpg)

La tension artérielle moyenne (**MAP**) se détermine ensuite d'après la formule suivante :

$$MAP = DP + 1/3*(SP-DP)$$

La tension artérielle moyenne optimale va être comprise entre 80 et 107. Les études ont montré que la MAP augmente avec l'âge. Elle s'explique entre autres par la perte d'élasticité des artères. Le surpoids a également un effet, ainsi qu'un cholestérol élevé dans les vaisseaux sanguins.

Le jeu de données suivant va vous permettre d'élaborer un modèle linéaire multiple pour mettre divers facteurs de risque en relation avec la MAP... mais il va avoir besoin d'un petit toilettage avant.

```{r, echo=TRUE, warning=FALSE}
diabetes <- read("diabetes", package = "faraway")
# Nettoyage du jeu de données
diabetes <- janitor::clean_names(diabetes)
skimr::skim(diabetes)
# Transformation de la masse de livres en kg
diabetes <- smutate(diabetes, weight = weight * 0.453592)
# Libellés et unités de différentes variables en français
diabetes <- labelise(diabetes, label = list(
  age = "Âge", chol = "Cholestérol total", glyhb = "Hémoglobine glycosylée", weight = "Masse"),
  units = list(age = "années", weight = "kg"))
# Some columns are of class "labelled", we convert them into numeric
is.labelled <- function(x) inherits(x, c("labelled", "haven_labelled"))
diabetes <- smutate(diabetes, across(sapply(diabetes, is.labelled), .fns = as.numeric))
```

> La dernière instruction mérite une petite explication. Nous avons plus d'une dizaine de variables dans le jeu de données qui ont la classe "labelled". Ce sont toutes des données quantitatives numériques et nous les voulons comme telles. Les transformer une à une explicitement serait fastidieux. Alors, nous avons fait appel ici à la fonction `across()` qui applique une transformation via son argument `.fns=` (ici, `as.numeric`) sur toutes les colonnes dont le nom est donné par le premier argument, ou via un vecteur de valeurs logiques de même taille que le nombre de variables du tableau. Comme nous voulons transformer toutes les colonnes qui héritent de la classe "labelled", nous appliquons le test sur toutes les colonnes (la fonction `sapply()` s'en charge) à l'aide de `is.labelled` définie juste au dessus qui fait ce test. Cela équivaut à utiliser `is.labelled(X)` avec `X` qui vaut tour à tour chacune des variables du tableau. Avec la function tidy `mutate()`, on aurait aussi pu écrire `across(where(is.labelled), .fns = as.numeric)`, mais `where()` n'est pas (encore) disponible pour les fonctions speedy comme `smutate()`.

Revenons sur nos données. Elles ont été collectées au sein d'une population afro-américaine dans l'état de Virginie aux USA dans le but d'étudier la prévalence du diabète, de l'obésité, et d'autres facteurs de risques cardio-vasculaires. Dans le cadre de cet exercice, nous allons nous limiter à quelques variables. Les pressions systoliques et diastoliques ont été mesurées deux fois : `bp.1s` pour la première systolique, `bp.1d` pour la première diastolique, et `bp.2s`, `bp.2d` pour la seconde série de mesures. Vous n'utiliserez que la première série. L'âge est exprimé en années dans la variable `age`, le cholestérol total est dans `chol`, l'hémoglobine glycosylée dans `glyhb`, une mesure indicatrice de diabète, la masse est `weight`, en kg.

## Pression artérielle moyenne

Débutez votre étude par le calcul de la variable `map` à partir de `bp.1s` et `bp.1d` du tableau `diabetes`. Pour rappel, la formule est :

$$MAP = DP + 1/3*(SP-DP)$$

Réalisez ensuite dans la foulée un graphique en nuage de points de la pression artérielle moyenne en fonction de l'âge.

```{r chart_h2, exercise=TRUE}
diabetes <- smutate(diabetes,
  map = ___ |> labelise("Tension artérielle moyenne", units = "___"))

chart(data = ___, ___ ~ ___) +
  geom____(na.rm = TRUE)
```

```{r chart_h2-hint-1}
diabetes <- smutate(diabetes,
  map = bp_1d + ___ * (___ - ___) |> labelise("Tension artérielle moyenne", units = "mm Hg"))

chart(data = ___, ___ ~ ___) +
  geom_point(na.rm = TRUE)

#### ATTENTION: Hint suivant = solution !####
```

```{r chart_h2-solution}
## Solution ##
diabetes <- smutate(diabetes,
  map = bp_1d + 1/3 * (bp_1s - bp_1d) |> labelise("Tension artérielle moyenne", units = "mm Hg"))

chart(data = diabetes, map ~ age) +
  geom_point(na.rm = TRUE)
```

```{r chart_h2-check}
grade_code("Vous venez de calculer MAP et de représenter graphiquement MAP en fonction de l'âge. Que voyez-vous d'intéressant sur ce graphique ?")
```

```{r}
diabetes <- smutate(diabetes,
  map = bp_1d + 1/3 * (bp_1s - bp_1d) |> labelise("Tension artérielle moyenne", units = "mm Hg"))
```

Prenez l'habitude d'étudier la matrice de corrélation entre toutes les variables qui vont entrer potentiellement dans votre modèle.

```{r, echo=TRUE}
correlation(diabetes[, c("map", "age", "chol", "glyhb", "weight")], use = "complete.obs")
```

> En présence de valeurs manquantes, l'argument `use=` permet de spécifier quoi faire. `"complete.obs"` ne prend en compte que les observations pour lesquelles il n'y a aucune valeur manquante pour aucune des cinq variables, voir `?correlation()`.

Ici, nous sommes en présence de corrélations très faibles entre les variables potentiellement explicatives et MAP. Ce n'est pas une bonne nouvelle. Nous pouvions déjà constater cela sur le graphique entre la MAP et l'âge avec un nuage de points très peu étiré. La bonne nouvelle, c'est que les quatre variables explicatives sont également peu corrélées entre elles, et aussi que nous avons plusieurs centaines d'individus mesurés dans notre échantillon.

## Modélisation

Élaborez le meilleur modèle de régression multiple dans `map_lm` en partant de `age`, `chol`, `glyhb`, et `weight`dans cet ordre comme variables explicatives pour expliquer `map`. Simplifiez éventuellement votre modèle si c'est nécessaire. Produisez ensuite le résumé de votre analyse.

```{r regmulti2_h2, exercise=TRUE}
map_lm <- lm(data = ___, ___ ~ ___)
# Résumé du modèle
summary(___)
```

```{r regmulti2_h2-hint-1}
map_lm <- lm(data = ___, ___ ~ ___)
# Résumé du modèle
summary(map_lm)
#### ATTENTION: Hint suivant = solution !####
```

```{r regmulti2_h2-solution}
## Solution ##
map_lm <- lm(data = diabetes, map ~ age + chol + weight)
# Résumé du modèle
summary(map_lm)
```

```{r regmulti2_h2-check}
grade_code("Bon, voilà notre régression multiple pour laquelle il nous a fallu laisser tomber `glyhb`, la mesure liée au diabète, qui n'a manifestement pas de relation avec la tension artérielle moyenne. Le R^2^ est très faible avec 11%, mais le modèle est significatif au seuil alpha de 5% avec une ANOVA qui renvoie une valeur P très largement inférieure à ce seuil (tout en bas à droite de la sortie résumé).")
```

Analysez les résultats ci-dessus et répondez aux questions suivantes :

```{r qu_regpoly}
quiz(
  question(text = "Quelle est la valeur de l'ordonnée à l'origine pour ce modèle ?",
    answer(sprintf("%.4f", map_lm_coef$estimate[1]), correct = TRUE),
    answer(sprintf("%.4f", map_lm_coef$estimate[2])),
    answer(sprintf("%.4f", map_lm_coef$std.error[1])),
    answer(sprintf("%.4f", map_lm_coef$std.error[2])),
    answer(sprintf("%.4f", map_lm_coef$statistic[1])),
    answer(sprintf("%.4f", map_lm_coef$statistic[2])),
    answer(sprintf("%.4f", map_lm_param$r.squared[1])),
    allow_retry = TRUE, random_answer_order = TRUE
    ),
  question(text = "Quelle est l'erreur standard pour le paramètres lié à l'âge ?",
    answer(sprintf("%.2f", map_lm_coef$estimate[1])),
    answer(sprintf("%.2f", map_lm_coef$estimate[2])),
    answer(sprintf("%.2f", map_lm_coef$std.error[1])),
    answer(sprintf("%.4f", map_lm_coef$std.error[2]), correct = TRUE),
    answer(sprintf("%.2f", map_lm_coef$statistic[1])),
    answer(sprintf("%.2f", map_lm_coef$statistic[2])),
    answer(sprintf("%.2f", map_lm_param$adj.r.squared[1])),
    allow_retry = TRUE, random_answer_order = TRUE
    )
)
```

Voici l'analyse des résidus de ce modèle. Prenez le temps d'interpréter ces graphiques.

```{r}
chart$residuals(map_lm)
```

Ce second exemple vous a permis, outre de vous exercer à ajuster un modèle linéaire multiple, de réaliser que significativité du modèle et des ses paramètres d'une part (ANOVA de la régression et tests de Student des paramètres), et qualité d'ajustement d'autre part (R^2^) ne vont pas forcément de pair. Il est pratiquement impossible d'avoir un R^2^ élevé et une régression non significative. Cependant, l'inverse est possible comme ici pour `diabetes`, soit un R^2^ très très faible qui ne permet pas de faire des prédictions de la MAP à partir de l'âge, du cholestérol sanguin ou de la masse, mais une régression et des paramètres qui sont pourtant tous significatifs. Ce modèle est utile parce qu'il confirme que ces trois variables explicatives -âge, cholestérol et masse- sont belles et bien associées à l'hypertension artérielle. Mais par contre, oubliez ce modèle pour effectuer des prédictions de la MAP !

## Conclusion

Vous venez de terminer ce tutoriel sur la régression multiple. Vous avez appris à sélectionner judicieusement vos variables explicatives et à analyser avec un œil critique les résultats obtenus via le résumé et les graphiques d'analyse des résidus. Vous êtes maintenant prêt à vous attaquer à un projet GitHub Classroom sur ce sujet.

```{r comm_noscore, echo=FALSE}
question_text(
  "Laissez-nous vos impressions sur ce learnr",
  answer("", TRUE, message = "Pas de commentaires... C'est bien aussi."),
  incorrect = "Vos commentaires sont enregistrés.",
  placeholder = "Entrez vos commentaires ici...",
  allow_retry = TRUE,
  submit_button = "Soumettre une réponse", 
  try_again_button = "Resoumettre une réponse"
)
```
