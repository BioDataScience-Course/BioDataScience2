---
title: "sdd2-mod02 : régression linéaire polynomiale"
author: "Guyliann Engels & Philippe Grosjean"
description: "Application des concepts liés la régression linéaire polynomiale."
output:
  learnr::tutorial
tutorial:
  id: "sdd2.02b"
  version: 1.1.0
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(knitr)
SciViews::R()
library(BioDataScience)

options(tutorial.event_recorder = BioDataScience::record_sdd)
tutorial_options(exercise.checker = BioDataScience::checker_sdd)
tutorial_options(exercise.timelimit = 60)
tutorial_options(exercise.cap = "Code R")
knitr::opts_chunk$set(echo = FALSE, comment = NA)
```

```{r, echo=FALSE}
fixedRow(
  column(9, div(
    img(src = 'images/BioDataScience-128.png', align = "left"),
    h1("Science des données biologiques 2"),
    "Réalisé par le service d'Écologie numérique des Milieux aquatiques, Université de Mons (Belgique)"
  )),
  column(3, div(
    textInput("user", "Utilisateur :", ""),
    textInput("email", "Email :", "")
  ))
)
textOutput("user") # This is newer shown, but required to trigger an event!
textOutput("email") # Idem!
```

```{r, context="server"}
output$user <- renderText({BioDataScience::user_name(input$user);""})
output$email <- renderText({BioDataScience::user_email(input$email);""})
updateTextInput(session, "user", value = BioDataScience::user_name())
updateTextInput(session, "email", value = BioDataScience::user_email())
```

## Préambule

Si vous n'avez jamais utilisé de tutoriel "learnr", familiarisez-vous d'abord avec son interface [ici](http://biodatascience-course.sciviews.org/sdd-umons/learnr.html).

![](images/attention.jpg)

**Ne vous trompez pas dans votre adresse mail et votre identifiant Github**

**N'oubliez pas de soumettre votre réponse après chaque exercice**

> Conformément au RGPD ([Règlement Général sur la Protection des Données](https://ec.europa.eu/info/law/law-topic/data-protection/reform/rules-business-and-organisations/principles-gdpr_fr)), nous sommes tenus de vous informer de ce que vos résultats seront collecté afin de suivre votre progression. **Les données seront enregistrées au nom de l'utilisateur apparaissant en haut de cette page. Corrigez si nécessaire !** En utilisant ce tutoriel, vous marquez expressément votre accord pour que ces données puissent être collectées par vos enseignants et utilisées pour vous aider et vous évaluer. Après avoir été anonymisées, ces données pourront également servir à des études globales dans un cadre scientifique et/ou éducatif uniquement.

## Régression linéaire polynomiale

```{r regpoly-init}
# edition de l'exercice 
set.seed(42)

x <- seq(from = 1, to = 10, by = 0.25)
x1 <- x + rnorm(n = length(x))


mod_poly2 <- function(x1, alpha1, alpha2, intercept, random_effect){
  y <- intercept + (alpha1 * x1) + (alpha2 * (x1^2)) 
  y + rnorm(n = length(x1), sd = random_effect)
}

df <- tibble(
  x = x1,
  y = mod_poly2(x1 = x1, alpha1 = 2, alpha2 = 2.5, intercept = 55, random_effect = 10)
)

lm_poly <- lm(df, formula = y ~ x + I(x^2))
lm_poly_coef <- broom::tidy(lm_poly)
lm_poly_param <- broom::glance(lm_poly)
```

Réalisez la régression linéaire polynomiale d'ordre 2 de la variable `y` en fonction de la variable `x` sur le jeu de données `df`. Vous avez à votre dispositon un nuage de points et un résumé des données pour avoir une première connaissance de données.

```{r}
chart(df, y ~ x) +
  geom_point()
```

```{r regpoly-prep}
# copie du chunk regpoly-init
# edition de l'exercice 
set.seed(42)

x <- seq(from = 1, to = 10, by = 0.25)
x1 <- x + rnorm(n = length(x))


mod_poly2 <- function(x1, alpha1, alpha2, intercept, random_effect){
  y <- intercept + (alpha1 * x1) + (alpha2 * (x1^2)) 
  y + rnorm(n = length(x1), sd = random_effect)
}

df <- tibble(
  x = x1,
  y = mod_poly2(x1 = x1, alpha1 = 2, alpha2 = 2.5, intercept = 55, random_effect = 10)
)
```


```{r regpoly, exercise = TRUE, exercise.setup = "regpoly-prep"}
# Résumé des données
summary(df)
# 


```

```{r regpoly-hint-1}
#snippet
summary(lm. <- lm(data = DF,
  YNUM ~  XNUM + I(XNUM^2)))
lm. %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2)))(.)
```

```{r regpoly-solution}
summary(lm. <- lm(data = df,
  y ~  x + I(x^2)))
lm. %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2)))(.)
```

```{r regpoly-check}
# TODO 
```

Suite à votre analyse répondez aux questions suivantes

```{r qu_regpoly}
quiz(
  question(text = "Quelle est la valeur de l'ordonnée à l'origine ?",
    answer(sprintf("%.2f", lm_poly_coef$estimate[1]), correct = TRUE),
    answer(sprintf("%.2f", lm_poly_coef$estimate[2])),
    answer(sprintf("%.2f", lm_poly_coef$std.error[1])),
    answer(sprintf("%.2f", lm_poly_coef$std.error[2])),
    answer(sprintf("%.2f", lm_poly_coef$statistic[1])),
    answer(sprintf("%.2f", lm_poly_coef$statistic[2])),
    answer(sprintf("%.2f", lm_poly_param$r.squared[1])),
    allow_retry = TRUE, random_answer_order = TRUE
    ),
  question(text = "Quelle est la valeur de **x** ?",
    answer(sprintf("%.2f", lm_poly_coef$estimate[1])),
    answer(sprintf("%.2f", lm_poly_coef$estimate[2]), correct = TRUE),
    answer(sprintf("%.2f", lm_poly_coef$std.error[1])),
    answer(sprintf("%.2f", lm_poly_coef$std.error[2])),
    answer(sprintf("%.2f", lm_poly_coef$statistic[1])),
    answer(sprintf("%.2f", lm_poly_coef$statistic[2])),
    answer(sprintf("%.2f", lm_poly_param$r.squared[1])),
    allow_retry = TRUE, random_answer_order = TRUE
    )
)
```

## Régression linéaire simple ou polynomiale

```{r regpoly_simp-init}
# edition de l'exercice 
set.seed(42)

x <- seq(from = 1, to = 10, by = 0.25)
x1 <- x + rnorm(n = length(x))


mod_poly2 <- function(x1, alpha1, alpha2, intercept, random_effect){
  y <- intercept + (alpha1 * x1) + (alpha2 * (x1^2)) 
  y + rnorm(n = length(x1), sd = random_effect)
}

df <- tibble(
  x = x1,
  y = mod_poly2(x1 = x1, alpha1 = 2, alpha2 = 2.5, intercept = 55, random_effect = 10)
)

lm_lin_simp <- lm(df, formula = y ~ x )
lm_ls_coef <- broom::tidy(lm_lin_simp)
lm_ls_param <- broom::glance(lm_lin_simp)

lm_lin_poly <- lm(df, formula = y ~ x + I(x^2))
lm_lp_coef <- broom::tidy(lm_poly)
lm_lp_param <- broom::glance(lm_poly)
```

Réalisez une régression linéaire simple et une régression linéaire polynomiale d'ordre 2 de la variable `y` en fonction de la variable `x` sur le jeu de données `df`. Utilsez le critère d'Akaike afin de déterminer le meilleur modèle. Vous avez à votre dispositon un nuage de points et un résumé des données pour avoir une première connaissance de données.

```{r}
chart(df, y ~ x) +
  geom_point()
```


```{r regpoly_simp-prep}

# edition de l'exercice 
set.seed(42)

x <- seq(from = 1, to = 10, by = 0.25)
x1 <- x + rnorm(n = length(x))


mod_poly2 <- function(x1, alpha1, alpha2, intercept, random_effect){
  y <- intercept + (alpha1 * x1) + (alpha2 * (x1^2)) 
  y + rnorm(n = length(x1), sd = random_effect)
}

df <- tibble(
  x = x1,
  y = mod_poly2(x1 = x1, alpha1 = 2, alpha2 = 2.5, intercept = 55, random_effect = 10)
)

lm_lin_simp <- lm(df, formula = y ~ x )
lm_ls_coef <- broom::tidy(lm_lin_simp)
lm_ls_param <- broom::glance(lm_lin_simp)

lm_lin_poly <- lm(df, formula = y ~ x + I(x^2))
lm_lp_coef <- broom::tidy(lm_lin_poly)
lm_lp_param <- broom::glance(lm_lin_poly)
```

```{r regpoly_simp, exercise = TRUE, exercise.setup = "regpoly_simp-prep"}
# résumé 
summary(df)
#
#
```


```{r regpoly_simp-hint-1}
# snippet
summary(lm. <- lm(data = DF,
  YNUM ~  XNUM + I(XNUM^2)))
lm. %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2)))(.)
```

```{r regpoly_simp-hint-2}
# snippet (suite)
summary(lm. <- lm(data = DF, YNUM ~ XNUM))
lm. %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x))(.)
```

```{r regpoly_simp-hint-3}
# snippet (suite)
AIC(lm.)
```

```{r regpoly_simp-solution}
summary(lm_lin_poly <- lm(data = df,
  y ~  x + I(x^2)))
summary(lm_lin_simp <- lm(data = df,
  y ~  x ))
AIC(lm_lin_poly, lm_lin_simp)
```

```{r regpoly_simp-check}
# TODO 
```

Suite à votre analyse répondez aux questions suivantes

```{r qu_regpoly_simp}
quiz(
  question(text = "Quelle est la valeur du critère d'Akaike de la régression polynomiale ?",
           answer(sprintf("%.2f", lm_lp_param$AIC), correct = TRUE),
           answer(sprintf("%.2f", lm_lp_param$BIC)),
           answer(sprintf("%.2f", lm_lp_param$sigma)),
           answer(sprintf("%.2f", lm_lp_param$deviance)),
           allow_retry = TRUE, random_answer_order = TRUE
           ),
  question(text = "Quelle est la valeur du critère d'Akaike de la régression linéaire simple ?",
           answer(sprintf("%.2f", lm_ls_param$AIC), correct = TRUE),
           answer(sprintf("%.2f", lm_ls_param$BIC)),
           answer(sprintf("%.2f", lm_ls_param$sigma)),
           answer(sprintf("%.2f", lm_ls_param$deviance)),
           allow_retry = TRUE, random_answer_order = TRUE
           ),
  question(text = "Quel est le meilleur modèle selon le critère d'Akaike",
           answer("modèle linéaire polynomiale", correct = TRUE),
           answer("modèle linéaire simple"),
           allow_retry = TRUE
           )
)
```


## Conclusion

Vous venez de terminer votre séance d'exercice.

Laissez nous vos impressions sur cet outil pédagogique ou expérimentez encore dans la zone ci-dessous. Rappelez-vous que pour placer un commentaire dans une zone de code R, vous devez utilisez un dièse (`#`) devant vos phrases.

```{r comm, exercise=TRUE, exercise.lines = 8}
# Ajout de commentaires 
# ...
```

```{r comm-check}
# Not yet...
```
